% The figure for showing the overall approaches.
\begin{figure*}[!tbp]
    \renewcommand{\arraystretch}{1}
        \centering
        \includegraphics[width=\textwidth]{figures/approach_fig.pdf}\hfill
        \caption{Overall structure of the {\simfin} and {\simfinmo} approach.}
        \label{fig:approach}
    \end{figure*}
    
     
    \section{Approach}
    In this section, we will explain about the details in implementing our new paradigm of defect prediction model using the similar commit search engine, {\simfin}. A figure of the overall approach is depicted in Fig. \ref{fig:approach}.
    
    \subsection{Collecting Bug Inducing Changes}
    In the beginning, we use a tool called the Bug Patch Collector to collect change data to form a training data for the {\simfin}.
    First, the tool uses SZZ algorithm \cite{sliwerski2005changes} to collect BICs. 
    Bug Patch Collector mines bug fixing changes (BFC) from issue tracking system such as JIRA.
    The issue tracking system manages all issues that have occurred during the development of the project.
    The issue is labeled according to the type, status and resolution.
    To find the bug-fix issue, we look for issues that are labelled as the following: type that are labelled ``Bug'', status that are labelled ``Closed'' or ``Resolved'' and resolution that are labelled ``Fixed''.
    
    Projects that are managed by JIRA include issue keys which are unique numbers of issues and used in commit messages.
    Therefore, by using the issue key of bug fix issue, we can find BFCs.
    In BFC, it is quite probable that the deleted lines are the part that causes bugs and added lines are the corresponding patches.
    We compare previous commit of the BFC and the actual BFC in each source, to extract deleted or replaced lines using git diff which is based on Myers diff algorithm \cite{myers1986ano}.
    Then, we apply git blame command to each modified line since git blame shows the information of last commit id, the author, the timestamp and the line number of code for the line.
    By using these piece of information, we can track the BIC.
    
    After collecting the BICs, we also collect all the other changes and label it as clean changes.
    We do this because {\simfin} exploits both BIC and clean changes in forming the search engine.
    
    \subsection{Collecting Change Vectors}
    After we retrieve the change data from the Bug Patch Collector, we use the Change Vector Collector to generate vectors from the change lists, both buggy and clean. 
    First, we collect the source code of before and after a change is applied. 
    Then we apply the Gumtree~\cite{falleri2014fine} algorithm, which is a source code tree differencing algorithm with a finer granularity than that of line differencing.
    We use Gumtree for differencing the two source code because finer granularity captures a more precise change.
    By capturing a finer granularity of change, we can accurately represent change while reducing the memory as well.
    We also want to capture less false positive changes (code parts that are not actually changed but identified as changed) to compactly represent the changes.
    Lastly, because the changes are represented in AST vectors, we can capture the syntactical change in the vectors so that the {\simfin} can capture the relations of the node's syntax change.

    If we apply Gumtree to the code before and after a change, the changed nodes will be represented as insertion, deletion, or update of a node or a move of a sub-tree.
    We only regard insertion and deletion of a node because updates and moves were mostly refactoring changes.
    However, they could be some other meaningful changes.
    So it can be regarded as sacrificing some instances for a denoising effect.
    After we collect each remaining changes, we encode each node-change with a unique integer value. 
    Then, we append each value in the order of its occurrence from top to bottom, left to right in the source code.
    After that, we append what we call the context vector.
    The context vector is the a list of neighboring nodes of each node-change.
    We collect the context vectors by taking the all descendant nodes of the parent node of each changed node.
    Then we disregard the descendant nodes by collecting nodes that are within 3 lines of each corresponding changed node.
    We also disregard duplication as there could be a number of redundant context nodes.
    We have chosen to use the context vector to capture a richer information of changes, so when we search for similar changes, we not only look at the change themselves but also the context where the change have taken.
    The label data for {\simfin} is also constructed in this phase.
    For the label, we use the key value of each change, which is the commit id and the source file path of each change. 
    The reason for making the label in such way is because when {\simfin} is given with a target commit, it predicts the closest commit in the repository.
    The key value should contain the id of the commit and the source file path of the change to return the most similar commit. In JIT DP, prediction granularity is a commit level. This means if multiple files are modified in one commit, JIT DP considers this as one change. However, to avoid this large change of one commit, we consider a change in an individual file of one commit. In other words, SimFin deals with more finer changes than those in JIT DP.
    
    \subsection{SimFin: Similar Commit Change Finder}
    As in Fig.~\ref{fig:approach}, {\simfin} is composed of a pair of deep auto encoder-decoder and k-Nearest Neighborhood (kNN) models. {\simfin} takes the vectors as Change Vector Collector returns.
    One set of auto encoder-decoder model and a kNN model is built from BIC instances and another set of models are built from clean instances. 
    The change vectors are first encoded through deep feature learning using auto-encoder decoder model.
    Then the encoded features are fed to a kNN model to search the nearest commit change from the target commit.
    %Then, {\simfinmo}, which is a prediction model, computes a distane ratio of buggy and clean changes searched by {\simfin} and predict the bug-proneness of the target commit.
    
    \subsubsection{Auto Encoder-Decoder Model}
    Auto encoder-decoder model in {\simfin} is used to learn and encode the relationship of the syntactical feature and its semantics.
    First, we apply zero padding to all the training instances to match dimension size.
    Then, the encoder encodes the vector by passing through the deep layers of the encoder network.
    Then it is reconstructed by passing through the deep layers of the decoder network.
    The reconstruction error is used to backpropagate through the network and update the weights to reduce the error.
    The settings we used for the auto encoder-encoder model is 10 layers for each networks, 500 nodes for each layer, 20 epochs, and a batch size of 512.
    We used ReLU at each layers for the activation function and a Sigmoid function at the last layer of the decoder.
    Binary cross-entropy was used for the loss function and Ada-delta was used for the optimizer.
    We use the decoder end of the networks to update the weight of the encoder model, but we only use the encoder part of the network to encode testing project in prediction phase.
    The BIC instances and the clean instances are trained into separate networks of auto encoder-decoder model.
    We trained the networks separately because we made a presumption that BIC and clean changes have different semantics.
    
    \subsubsection{k-Nearest Neighborhood}
    After we encode the syntactic and semantic representations of changes, we feed them to a kNN model to find similar changes which is the closest data point in the vector space.
    The kNN model originally makes prediction of an instance's class with respect to the distance in the vector space.
    The labels are usually a binary or multi-class of labels, however, we use commit key as the label which is a unique label.
    This is done because we want to search the closest commit to the target commit.
    All the label in kNN model, Fig. \ref{fig:approach}, is depicted as different icons to show that each labels are unique.
    Because of this nature, it is not able to, or not sensible, to get the evaluation score of the kNN.
    Similar to auto encoder-decoder model, the kNN models are also trained separately from BIC instances and clean instances.
    Thus, we finally have buggy {\simfin} and clean {\simfin} respectively.
    
    \subsection{Prediction}
    In the prediction phase, the target commit, buggy or clean, has to go through the Change Vector Collector phase, auto encoder-decoder phase, and the kNN model phase. It is very similar to the training scenario.
    The change vectors, together with the context vectors, are generated from applying the Gumtree algorithm.
    The semantic representation of the change is learned from the encoder that is trained before-hand.
    Lastly, the learned feature representation is plotted in the vector space of kNN model, which then searches for nearest changes.
    Because we have different set of models, one (buggy \simfin) made from BIC and another (clean \simfin) from clean instances, we plot the target change in both vector spaces.
    After plotting the target change into both spaces, we search for the closest change in each space. Then, we can get the closest distance value in the BIC space divided by the closest distance value in the clean space. By using these two values, we can compute the distance ratio as follows:
    \begin{equation}
        DR = \frac{\delta_b}{\delta_c}
    \end{equation}
    where $\delta_b$ is a the closest distance value from buggy \simfin while $\delta_c$ is a the closest distance value from clean \simfin.
    If a target change has a closer distance of a similar change from buggy \simfin than that from clean \simfin, $DR$ is always less than 1. Otherwise, $DR$ is 1 or greater.
    The intuition behind this method is that if a target change is very close to the closest BIC and is very far away from the closest clean instance, it is more likely to be buggy.
    On the contrary, if the target change is far away from the closest BIC instance but it is closer to the closest clean instance, it is more likely to be clean. Here, we need to set the cutoff value for $DR$ values to decide whether the target change is buggy or clean.
    If we set a cutoff as 1 for \simfinmo and $DR$ is less than this predefined cutoff value, we predict it as buggy. Since $DR=1$ implies the target change has the same closest distance values from both boggy and clean \simfin, we use 1 as a default cutoff for \simfinmo.
    
    After predicting a target change as buggy, then \simfinmo suggests the bug fix change (BFC) of the closest buggy change from buggy \simfin. This BFC can be used as a bug fix hint of the target change and can be an actionable message for a developer.