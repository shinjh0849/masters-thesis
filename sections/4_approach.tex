% The figure for showing the overall approaches.
\begin{figure*}[!tbp]
\renewcommand{\arraystretch}{1}
    \centering
    \includegraphics[width=\textwidth]{figures/approach_fig.pdf}\hfill
    \caption{Overall structure of the {\simfin} and {\simfinmo} approach.}
    \label{fig:approach}
\end{figure*}
    
     

This chaper details the implementation of {\simfinmo}.
The overall approach of {\simfinmo} is illustrated in Fig. \ref{fig:approach}.

\section{Data Collection}
We mined bug-inducing commits (BICs) and clean commits from software repositories to train the {\simfin}.
First, we used the SZZ algorithm \cite{sliwerski2005changes} to collect BICs from software repositories. 
The SZZ algorithm first mined bug fixing changes (BFC) from issue tracking system such as JIRA.
The issue tracking system manages all issues that have occurred during the development of the project.
The issue is labeled according to the type, status and resolution.
To find the bug-fix issue, we look for issues that are labeled as the following: type that are labeled ``Bug'', status that are labeled ``Closed'' or ``Resolved'' and resolution that are labeled ``Fixed''.

Projects that are managed by JIRA include issue keys which are unique numbers of issues and used in commit messages.
Therefore, by using the issue key of bug fix issue, we can find BFCs.
The deleted lines in the BFC are considered to be the buggy code while the added lines are the corresponding patches.
We compare previous commit of the BFC and the actual BFC in each source, to extract deleted or replaced lines using git diff which is based on Myers diff algorithm \cite{myers1986ano}.
Then, we apply git blame command to each modified line since git blame shows the information of last commit id, the author, the timestamp and the line number of code for the line.
By using these piece of information, we mined the BIC.

After collecting the BICs, we also collect all the other changes and label it as clean changes.
We do this because {\simfin} exploits both BIC and clean changes in forming the search engine.

\section{Vector Embedding}
We vectorized the change data after mining them from software repositories
First, we collect the source code of a change applied the Gumtree~\cite{falleri2014fine} algorithm.
We use Gumtree for differencing the two source code because finer granularity captures a more precise change.
By capturing a finer granularity of change, we can accurately represent change while reducing the memory as well.
We also want to capture less false positive changes (code parts that are not actually changed but identified as changed) to compactly represent the changes.
Lastly, because the changes are represented in AST vectors, we can capture the syntactical change in the vectors so that the {\simfin} can capture the relations of the node's syntax change.

If we apply Gumtree to the code before and after a change, the changed nodes will be represented as insertion, deletion, or update of a node or a move of a sub-tree.
We only regard insertion and deletion of a node because updates and moves were mostly refactoring changes.
However, they could be some other meaningful changes.
So it can be regarded as sacrificing some instances for a denoising effect.
After we collect each remaining changes, we encode each node-change with a unique integer value. 
Then, we append each value in the order of its occurrence from top to bottom, left to right in the source code.
By doing this, we can capture the syntactic characteristic as well as the order information of the change.
After that, we append what we call the context vector.
The context vector is the a list of neighboring nodes of each node-change.
We collect the context vectors by taking the all descendant nodes of the parent node of each changed node.
Then we disregard the descendant nodes by collecting nodes that are within 3 lines of each corresponding changed node.
We also disregard duplication as there could be a number of redundant context nodes.
We have chosen to use the context vector to capture a richer information of changes, so when we search for similar changes, we not only look at the change themselves but also the context where the change have taken.
The label data for {\simfin} is also constructed in this phase.
For the label, we use the key value of each change, which is the commit id and the source file path of each change. 
The reason for making the label in such way is because when {\simfin} is given with a target commit, it identifies the closest commit in software repositories.
The key value should contain the id of the commit and the source file path of the change to return the most similar commit.

\section{{\simfin}: Similar Change Finder}
{\simfin} is composed of a deep auto encoder-decoder (AED) and a k-Nearest Neighborhood (kNN) model.
The deep AED model first encodes the embedded syntactic vectors from Gumtree and learns the semantics of changes.
Then the kNN model computes distances of each data points of changes and returns the closest \emph{k} changes and its distance.

\subsection{Number of {\simfin}s}
First, we have built one {\simfin} where all the BICs and clean changes are trained together.
This is reasonable as we are going to use the ratio of the distance value of closest BIC and the clean change to the target change in identifying the defect.
By plotting all the changes in the same encoding space, the degree of distance between the target change and both clean and buggy changes will have the same degree.

Second, we also built two separate {\simfin} where one pair of AED and kNN model is trained with buggy change instances and the other with clean change instances.
When we build two separate {\simfin} models, the encoding space of buggy and clean changes become different, hence using there distance ration can be insensible.
However, due to the data size of clean changes and buggy changes being extremely imbalanced (around 26 : 1), looking for the closest buggy and clean changes within a certain \emph{k} can show a very skewed result.

To alleviate these issues raised from imbalanced class, we trained a separate AED model to get the distance of the closest \emph{k} change instances in each buggy and clean data pool.
With \emph{k} numbers of closest distances in both pools, we hope to get the representative distance value of each pools.

For validity of choosing whether to train one or two different {\simfin}s, we compared the performance measure of the two methods in section VI.

\subsection{Auto Encoder-Decoder Model}
AED model in {\simfin} is used to learn and encode the relationship of the syntactic feature and its semantics.
First, we apply zero-padding to all the training instances to match the dimension size.
Then, the encoder encodes the vector by passing through the deep layers of the encoder network.
Then it is reconstructed by passing through the deep layers of the decoder network.
The reconstruction error is used to backpropagate through the network and update the weights to reduce the error.
The settings we used for the AED model is 5 layers for each networks, 500 nodes for each layer, 3 epochs, and a batch size of 256.
We used ReLU at each layers for the activation function and a Sigmoid function at the last layer of the decoder.
Binary cross-entropy was used for the loss function and Ada-delta was used for the optimizer.
The decoder of the network is used to update the weight of the encoder model, but we only use the encoder part of the network to encode the test projects in the prediction phase.
The BIC instances and the clean instances are trained into separate AED models.
We trained the networks separately because we made a presumption that BIC and clean changes have different characteristics.

\subsection{k-Nearest Neighborhood}
After we encode the syntactic and semantic representations of changes, we feed them to a kNN model to find similar changes which is the closest data point in the vector space.
The kNN model originally makes prediction of an instance's class with respect to the distance in the vector space.
The labels are usually a binary or multi-class of labels, however, we use commit key as the label which is a unique label.
This is done because we want to search the closest commit to the target commit.
All the label in kNN model, Fig. \ref{fig:approach}, is depicted as different icons to show that each labels are unique.
Because of this nature, it is not able to, or not sensible, to get the evaluation score of the kNN.
Similar to AED model, the kNN models are also trained separately from BIC instances and clean instances.
Thus, we finally have buggy {\simfin} and clean {\simfin} respectively.

\section{Prediction}
In the prediction phase, the target commit is vectorized and fed into the {\simfin}.
The change vectors, together with the context vectors, are generated from applying the Gumtree algorithm.
The semantic representation of the change is inferred from the encoder that is trained before-hand.
Lastly, the learned feature representation is plotted in the vector space of kNN model, which then searches for nearest changes.
Because we have different set of models, one (buggy \simfin) made from BIC and another (clean \simfin) from clean instances, we plot the target change in both vector spaces.
After plotting the target change into both spaces, we search for the closest change in each space.
Then, we can get the closest distance value in the BIC space and it divided by the closest distance value in the clean space.
By using these two values, we can compute the distance ratio as follows:
\begin{equation}
    DR = \frac{\delta_b}{\delta_c}
\end{equation}
where $\delta_b$ is a the closest distance value from buggy \simfin while $\delta_c$ is a the closest distance value from clean \simfin.
If a target change has a closer distance of a similar change from buggy \simfin than that from clean \simfin, $DR$ is always less than 1. Otherwise, $DR$ is 1 or greater.
The intuition behind this method is that if a target change is very close to the closest BIC and is very far away from the closest clean instance, it is more likely to be buggy.
On the contrary, if the target change is far away from the closest BIC instance but it is closer to the closest clean instance, it is more likely to be clean.
Here, we need to set the cutoff value for $DR$ values to decide whether the target change is buggy or clean.
If we set a cutoff as 1 for \simfinmo and $DR$ is less than this predefined cutoff value, we predict it as buggy.
Since $DR=1$ implies the target change has the same closest distance values from both boggy and clean \simfin, we use 1 as a default cutoff for \simfinmo.

After predicting a target change as buggy, then \simfinmo suggests the BFC of the closest buggy change from buggy \simfin.
This BFC can be used as a bug fix hint of the target change and can be an actionable message for a developer.