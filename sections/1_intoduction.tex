\section{Introduction}
As the complexity of software rises through time, the cost of quality assurance and maintenance of software development continues to arise as well.
To address this issue, numerous studies have been conducted for automated quality assurance tasks to reduce the cost of software development and maintenance, such as automatic program repair \cite{kim2013automatic, long2016automatic, mechtaev2016angelix}, automated test case generation \cite{ali2009systematic, anand2013orchestrated, lei2008ipog} defect detection \cite{pradel2012leveraging, pradel2018deepbugs, wang2016bugram}, defect prediction \cite{nam2017heterogeneous, wang2016automatically, zimmermann2009cross}.
Among them, defect prediction models have been actively studied to efficiently allocate testing resources to reduce development cost.
Software defect prediction uses static code metrics as features on machine learning predictors to predict module of code as buggy or not. 
However, like other techniques, defect prediction models face numerous challenges in practical usage.

\section{Main Issues of Defect Prediction}
There are several issues in defect prediction such as identifying relationship between feature metrics and the label, no consistency in adopting performance evaluation metrics, difficulty in gathering buggy data, lack of standard or general framework, lack of validity in the e
conomic benefit, and the validity of how to retrieve buggy data \cite{arora2015open, herbold2019issues}.
Apart from these issues, we want to tackle some other important issues that challenges the research field of defect prediction.

\subsection{Actionable Messages}
One of major limitation that defect prediction face is that the predicted results lack actionable or explainable messages for the developers to act upon \cite{lewis2013does}.
The traditional defect prediction model predicts source code modules, usually in a file or a method level, as risky according to their degree of complexity.
However, the prediction does not specify which part of the code is buggy or explains what problems the module is causing.
Due to this nature, it is difficult for the developer to act upon the prediction result or understand how the module is causing the program.
To alleviate this issue, Just-in-time (JIT) defect prediction got into attention \cite{kamei2012large}.
JIT defect prediction predicts bugs in the code change level.
With finer granularity of prediction, researchers aim to provide `practical' defect prediction models for developers.
However, the finer granularity doesn't solve the problem, because if the commit gets too big, the same problem occurs.
Besides, the approach still does not explain how the commit is causing problems to the software.
In other words, the models do not provide actionable messages for the bug-prone changes.

\subsection{Cold-start Problem}
The second major problem of traditional defect prediction models is the cold-start problem.
A cold-start problem occurs when the target system lacks historical data \cite{schein2002methods}. 
Because traditional defect prediction models are built with previous versions of the target system, it is impossible to apply on projects that are just being started.
To alleviate this problem, the study of cross-project defect prediction (CPDP) and heterogeneous defect prediction (HDP) got popular.
CPDP enables defect prediction to be applied on newly starting projects because the prediction models are trained from other existing projects (cross-project).
HDP enables CPDP even when the source project and the test project have different metrics as features.
Machine learning techniques can only be applied when the training data and the test data have the same dimension of features (Homogeneous), however, this case is not always met.
So, the development of HDP increases the range of projects that could be used as training data.
However, CPDP and HDP do not fully alleviate the cold-start problem in the JIT settings because the metrics need a certain degree of historical data, i.e. the time spent after the last commit (AGE), the number of developers that contributed to the commit (NDEV), the number of unique changes in the commit (NUC) in \cite{kamei2012large}.

\subsection{Class Imbalance Problem}
The last major problem is the class imbalance problem.
Class imbalance problem occurs when a certain class of a label outweighs other classes in numbers \cite{he2009learning}.
This is very common in defect prediction scenarios due to the nature of the data. 
Due to the lack of label information and imbalance of class, machine learning models suffer to correctly learn and predict buggy instances.

\subsection{Contribution}
To resolve these issues, we propose a new paradigm of defect prediction.
The basic idea of our approach is to search the target change from a pool of bug inducing changes (BIC) in existing repositories and use the distance value of the search to identify the target change as buggy or clean.
We call this model that searches for similar change as {\simfin} (\underline{Sim}ilar commit change \underline{Fin}der).
{\simfin} is a combination of auto encoder-decoder \cite{hinton2006reducing} model and a k-Nearest Neighbor algorithm \cite{duda1973pattern} that learns from a collection of buggy and clean changes in the existing repositories and calculates their distances.
By using {\simfin}, we devised {\simfinmo}, a \underline{\simfin}-based defect prediction \underline{Mo}del.
The intuition of {\simfin} is as follows.
If the target change is very similar to our searched change (with the lowest distance value, i.e. the closest change existing in a repository), it is most likely to be a buggy change.
If the target change is very different from our searched change, then it is more likely to be a clean change. Our approach is very novel because, in the prediction phase, we do not apply any machine learning algorithm as opposed to other existing defect prediction models.
Also, we do not need a certain period of historical data to collect metrics for test data.
For prediction, {\simfinmo} simply looks if the distance ratio of the searched buggy and clean changes to the target change is higher than the cutoff value or not.
With this approach, we could alleviate all the aforementioned limitations of defect prediction.

\vspace{3mm}
The contributions of our work is that:
\begin{enumerate}
    \item We propose a completely new paradigm of defect prediction approach.
    \item With our model, we can alleviate the lack of actionable messages by providing similar BFC that is associated to the searched BIC.
    \item We mitigate the cold-start problem because our model is a fully universal, and needs no single previous commit for a test instance because we do not use historical metrics.
    \item This approach is free from the class-imbalance problem because it does not use machine learning in the prediction phase.
\end{enumerate}


